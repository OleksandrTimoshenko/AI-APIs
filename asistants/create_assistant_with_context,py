from openai import OpenAI
import os
from dotenv import load_dotenv
import datetime

load_dotenv()

PROJECT_NAME = "ZERMATT APP"

os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")

client = OpenAI()

# Step 1: Create a new Assistant with File Search Enabled
assistant = client.beta.assistants.create(
  name=PROJECT_NAME + " AI assistant",
  instructions="You have accessed the " + PROJECT_NAME + " project data, if you find the answer to the question in it, you should provide an answer based on the information from the file, if not, you should mention that you have not found information for the answer and try to answer the question using your knowledge.",
  model="gpt-4o",
  tools=[{"type": "file_search"}],
)

### You can do Steps 2 and 3 every time when files changed

# Step 2: Upload files and add them to a Vector Store
vector_store = client.beta.vector_stores.create(name=PROJECT_NAME + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
file_paths = ["./trainingData/Troubleshooting_DEV_and_PROD_environments.pdf"]
file_streams = [open(path, "rb") for path in file_paths]
# Use the upload and poll SDK helper to upload the files, add them to the vector store,
# and poll the status of the file batch for completion.
file_batch = client.beta.vector_stores.file_batches.upload_and_poll(
  vector_store_id=vector_store.id, files=file_streams
)
# You can print the status and the file counts of the batch to see the result of this operation.
print(file_batch.status)
print(file_batch.file_counts)
print(vector_store.id)

# Step 3: Update the assistant to to use the new Vector Store
assistant = client.beta.assistants.update(
  assistant_id=assistant.id,
  tool_resources={"file_search": {"vector_store_ids": [vector_store.id]}},
)

print("Created assistand ID for " + PROJECT_NAME + ": " + assistant.id)